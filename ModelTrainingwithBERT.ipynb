{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of data loading and model training with BERT vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_DIR = os.path.join(\"..\", \"Solution\", \"data\")\n",
    "BERT_FEATURE_DIR = \"bert_output_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format training data\n",
    "\n",
    "`X` will be a matrix with `N` rows for the `N` texts in the training data, and `M` columns for the `M` features generated by BERT.\n",
    "\n",
    "`y` will be an array of `N` class labels for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(ORIGINAL_DATA_DIR, \"lang_id_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vectors = []\n",
    "with open(os.path.join(BERT_FEATURE_DIR, \"train.jsonlines\"), \"rt\") as infile:\n",
    "    for line in infile:\n",
    "        bert_data = json.loads(line)\n",
    "        for t in bert_data[\"features\"]:\n",
    "            # Only extract the [CLS] vector used for classification\n",
    "            if t[\"token\"] == \"[CLS]\":\n",
    "                # We only use the representation at the final layer of the network\n",
    "                bert_vectors.append(t[\"layers\"][0][\"values\"])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(bert_vectors)\n",
    "y = train_df[\"native_language\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\freez\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\freez\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(penalty=\"l2\", C=1.0)\n",
    "lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(ORIGINAL_DATA_DIR, \"lang_id_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vec_test = []\n",
    "with open(os.path.join(BERT_FEATURE_DIR, \"test.jsonlines\"), \"rt\") as infile:\n",
    "    for line in infile:\n",
    "        bert_data_test = json.loads(line)\n",
    "        for t in bert_data_test[\"features\"]:\n",
    "            # Only extract the [CLS] vector used for classification\n",
    "            if t[\"token\"] == \"[CLS]\":\n",
    "                # We only use the representation at the final layer of the network\n",
    "                bert_vec_test.append(t[\"layers\"][0][\"values\"])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 768)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(bert_vec_test)\n",
    "y_test = test_df[\"native_language\"].values\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arabic', 'Cantonese', 'Japanese', 'Korean', 'Mandarin', 'Polish',\n",
       "       'Russian', 'Spanish', 'Thai', 'Vietnamese'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr_model.predict(X_test)\n",
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test dataset: 0.4560\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test dataset: {:.4f}'.format(lr_model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#CONFUSION MATRIX\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.48      0.48      0.48       200\n",
      "   Cantonese       0.31      0.29      0.30       200\n",
      "    Japanese       0.47      0.53      0.50       200\n",
      "      Korean       0.46      0.42      0.44       200\n",
      "    Mandarin       0.31      0.32      0.31       200\n",
      "      Polish       0.48      0.48      0.48       200\n",
      "     Russian       0.51      0.57      0.54       200\n",
      "     Spanish       0.52      0.50      0.51       200\n",
      "        Thai       0.59      0.59      0.59       200\n",
      "  Vietnamese       0.42      0.39      0.40       200\n",
      "\n",
      "    accuracy                           0.46      2000\n",
      "   macro avg       0.45      0.46      0.45      2000\n",
      "weighted avg       0.45      0.46      0.45      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic - 10.4000\n",
      "Cantonese - 13.6000\n",
      "Japanese - 10.6000\n",
      "Korean - 10.7000\n",
      "Mandarin - 13.9000\n",
      "Polish - 10.5000\n",
      "Russian - 9.8000\n",
      "Spanish - 9.7000\n",
      "Thai - 8.2000\n",
      "Vietnamese - 11.4000\n"
     ]
    }
   ],
   "source": [
    "#CLASSIFICATION DATA WITH MISSCLASSIFICATION RATE\n",
    "test_df['y_pred'] = y_pred\n",
    "group = test_df.groupby('y_pred').count()\n",
    "group_vals = group['native_language']\n",
    "mcs = []\n",
    "for item in range(len(sorted(group.index))):\n",
    "    m = ((200 - conf[item][item] + (group_vals[item] - conf[item][item])) / 2000) * 100\n",
    "    mcs.append(m)\n",
    "a,b,c,d = precision_recall_fscore_support(test_df['native_language'], test_df['y_pred'])\n",
    "l = sorted(test_df['native_language'].unique())\n",
    "for i in range(10):\n",
    "    print(l[i], '- {:.4f}'.format(mcs[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Evaluation Findings:\n",
      "Total test data: 2000\n",
      "Incorrect prediction: 1088.0\n",
      "Correct prediction: 912.0\n"
     ]
    }
   ],
   "source": [
    "#SUMMARY\n",
    "print(\"Summary of Evaluation Findings:\")\n",
    "print(\"Total test data:\", test_df.shape[0])\n",
    "print(\"Incorrect prediction:\", np.array(mcs).sum()*10)\n",
    "print(\"Correct prediction:\", (test_df.shape[0] - np.array(mcs).sum()*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rbf = SVC(kernel = 'rbf', C=1e3, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rbf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3475"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rbf.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
